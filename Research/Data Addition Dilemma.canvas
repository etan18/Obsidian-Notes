{
	"nodes":[
		{"id":"0536baf1c59796a3","type":"group","x":-840,"y":-320,"width":1580,"height":440,"color":"5","label":"Datasets"},
		{"id":"6d579619e5718d40","type":"text","text":"**eICU**:\n- $160$k patients\n- $180$k ICU stays\n- Across $208$ hospitals\n- $5$-minute time series frequency","x":-540,"y":-100,"width":250,"height":200},
		{"id":"d171c75fc6dd5f36","type":"text","text":"**All of Us:** attribute-based cohort selection\n- $800$k+ participants\n- $400$k+ EHRs\n- Demographic data:\n\t- Race / Ethnicity\n\t- Sex at birth\n\t- Gender identity\n\t- Age\n\t- Deceased","x":-220,"y":-200,"width":250,"height":300},
		{"id":"629f777083d6ef88","type":"text","text":"### Dataset Protocol\nFrom *Data Addition Dilemma* and *YAIB*:\n- Data cleaning:\n\t- Selects $52$ features ($48$ dynamic, $4$ static) that are available across all datasets for most patients.\n\t- No data imputation\n- Exclusion criteria:\n\t- Invalid admission or discharge time\n\t- Less than $6$ hours spent in the ICU\n\t- $< 4$ hourly bins with clinical measurements\n\t- $\\ge 12$ consecutive hours with no clinical measurements at any point\n\t- Under $18$ years of age at admission\n\t- Additional task-specific exclusion criteria described in Fig. 7 and 8 of *YAIB*\n- Dataset formation:\n\t- Select groups with $>$ some threshold of samples (e.g. $12$ hospitals had over $2,000$ patient unit encounters)\n\t- Set a fixed train set size and test set size","x":-840,"y":160,"width":520,"height":560},
		{"id":"114884751dc3b5f0","type":"text","text":"**MIMIC-IV**: admission type cohort selection\n- $53$k patients\n- $75$k ICU stays\n- $1$-hour time series frequency\n","x":-820,"y":-100,"width":250,"height":200},
		{"id":"bd25ee4411308c01","type":"text","text":"**YAIB**: hospital-based cohort selection\n\n\n\n","x":-540,"y":-200,"width":250,"height":60},
		{"id":"0160462a22aa083e","type":"text","text":"#### Tabular Data","x":-380,"y":-300,"width":250,"height":60},
		{"id":"5d2563cb7677fb02","type":"file","file":"Machine Learning/Paper Summaries/data addition dilemma.md","x":-840,"y":-600,"width":790,"height":200,"color":"2"},
		{"id":"913a820f09db2de7","type":"file","file":"Machine Learning/Paper Summaries/data selection & composition.md","x":-20,"y":-600,"width":760,"height":200,"color":"2"},
		{"id":"89233f1e6e59c532","type":"text","text":"## Week of 01-08-25\n\nHypothesis: how much adding a subgroup/hospital's data helps or harms your target model's performance is dependent on how much ***new information*** it provides. Thus, the change in fairness metrics correlates with the KL divergence between the combined dataset and the *augmented* max-entropy distribution which satisfies specified fairness constraints.\n- Observations to motivate this claim:\n\t1. Scaling from the test hospital only (e.g. training on 1000 samples vs. 2000 samples) consistently improves performance among most hospitals, much not by much.\n\t2. In comparison, when we train a model on 1000 samples of test hospital $\\cup$ 1000 samples of another hospital, the resulting performance difference varies a lot, but generally we'll find a hospital that improves performance by *more* than if we just doubled the amount of training data from the test hospital only.\n- Open questions\n\t1. Are performance changes commutative/symmetric? i.e. is it generally true that if adding hospital X to hospital Y improves hospital Y's test accuracy, then adding Y to X will improve X's test accuracy?\n\t2. What information theory-based heuristics exist/have we already tested?\n\t3. Does the distribution of the added data still need to be similar to the test hospital?\n\n","x":800,"y":-610,"width":700,"height":730},
		{"id":"2f5a03b765dffe3d","type":"text","text":"### Mean Consistent Population Calibration\n\n**Setup:**\n- $\\mu_a$  : mean/expected value of outcome labels $Y_a$ in source $a$\n- $\\mu_b$   : mean/expected value of outcome labels $Y_b$ in source $b$\n- $f_{\\mathcal{D}_a}$ : predictor trained on source $a$ \n- $\\mu_{f_{\\mathcal{D}_a}}$: mean/expected value of predictions made by $f_{\\mathcal{D}_a}$ \n\nWe care specifically about the performance of the predictor on $a$.\n\nBase: start with a predictor $f_{\\mathcal{D}_{a+b}}$, where\n- Source $a$: target subgroup (e.g. White) within Hos N\n- Source $b$: all other subgroups (e.g. Black & Other) within Hos N\n\nOriginal mean consistency value is $|\\mu_{f_{\\mathcal{D}_{a+b}}} - \\mu_{a}|$ \n- Case 1: $|\\mu_{f_{\\mathcal{D}_{a+b}}} - \\mu_{a}| = 0$ , our predictor is mean consistent\n- Case 2: $|\\mu_{f_{\\mathcal{D}_{a+b}}} - \\mu_{a}| > 0$, our predictor is not mean consistent\n\nVisualization: mean consistency of each subgroup across all hospitals and correlation with AUC (left) and ACC( right). Accuracy is highly negatively correlated with mean consistency.\n\n![[Pasted image 20250124163747.png]]\n\n\n\n### Data Addition\nAdd source $c$ (could be a whole hospital or subgroup from a hospital) and train predictor $f_{\\mathcal{D}_{a+b+c}}$. The new mean consistency value is $|\\mu_{f_{\\mathcal{D}_{a+b+c}}} - \\mu_{a}|$.\n\n**Visualization**: $|\\mu_{f_{\\mathcal{D}_{a+b+c}}} - \\mu_{a}|$ - $|\\mu_{f_{\\mathcal{D}_{a+b}}} - \\mu_{a}|$ \n![[Pasted image 20250124161739.png]]","x":-290,"y":160,"width":1690,"height":1920}
	],
	"edges":[
		{"id":"b17f955b64036e21","fromNode":"0160462a22aa083e","fromSide":"bottom","toNode":"bd25ee4411308c01","toSide":"top"},
		{"id":"c480bbd6fe24f781","fromNode":"0160462a22aa083e","fromSide":"bottom","toNode":"d171c75fc6dd5f36","toSide":"top"},
		{"id":"22e8d08028b20248","fromNode":"bd25ee4411308c01","fromSide":"bottom","toNode":"6d579619e5718d40","toSide":"top"},
		{"id":"cd9f10448a659436","fromNode":"bd25ee4411308c01","fromSide":"left","toNode":"114884751dc3b5f0","toSide":"top"}
	]
}