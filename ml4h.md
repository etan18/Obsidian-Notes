### AIES Feedback

**Reviewer 1**
- [ ] The following Introduction sentence was unclear: “For example, ICU datasets consist of patient encounters from multiple hospitals or multiple admission departments.” ICU patients can be admitted from another unit or floor within the same hospital system or building. For example, a Medical-Surgical patient’s clinical condition worsens, requiring an ICU admission for a higher level of patient care to stabilize the patient. This “transfer” encounter will be recorded in the EHR. It is not the same as hospital records being merged into a research database like that of eICU Collaborative Research Database (eICU-CRD). Additionally, in light of U.S. requirements for interoperability and health information exchanges (HIEs), the MIMIC-IV database can incorporate external hospital records as part of the patient’s permanent chart, allowing clinicians to access more comprehensive historical information about the patient’s medical and surgical histories from other hospitals and physicians' private practices. 
	- The point in mentioning the above is to be careful with wording, especially since this conference is cross-disciplinary, as well as the complexity of managing and solving EHR data quality issues. Managing and solving healthcare data quality issues is challenging. Numerous factors contribute to the poor quality of data used in machine learning development, including the fact that AI practitioners may not be subject matter experts about the data they use for healthcare machine learning applications.   
  
- [ ] I recommend citing the following sentence: “The limited interoperability between different EHR systems has been an ongoing frustration with healthcare workers.” Which healthcare workers are frustrated with current interoperability standards and why? Interoperability has improved since the completion of the U.S. federal Meaningful Use program (around 2016). The establishment of HIEs, including the Continuity of Care Document (CCD) and Consolidated Clinical Document Architecture (C-CDA) standards, improved interoperability and sharing of patient information between hospitals and physician practices' EHR systems. However, there is still room for improvement.  
- [ ] Under the “Challenges Surrounding ICU Data” subsection, the following sentence introduces some confusion: “However, in the age of Big Data, it is becoming increasingly necessary to train on larger datasets, which is most easily achieved by combining data from multiple EHR systems.” I respectfully disagree with this notion. In the real practical world, it is not easy to combine data from multiple EHR systems. It is already challenging to migrate data from an existing EHR system to a new EHR system. Such implementations require a minimum of two years to complete. The more hospital workflows to account for, the more challenging it becomes. Combining datasets from various real-world EHR systems for research purposes will be equally or more difficult if the goal is to have high-quality EHR data for research purposes.

From a practical standpoint, or in translating this work into healthcare practice settings, I question its soundness. The practicality of the paper’s intervention is not a solved issue because it needs to be tested on actual, real-world, modern EHR data, which are typically messier and more complicated than the data taken from the eICU-CRD and MIMIC-IV databases. How can hospital-based AI practitioners use their hospital's EHR data and adapt the data interventions the author(s) described in this paper to improve sub-population fairness? This is not clear in this paper. Hospital systems cannot easily retrieve another hospital’s EHR data and use it to enhance the sub-population fairness of the dataset used to develop a machine learning model in these settings.

**General Feedback**
Narrow scope:
- [ ] Focus is narrowly scoped: only binary ICU mortality prediction, logistic regression, and race as the sensitive attribute.  
	- In the Introduction the authors identify the task-dependent nature of data addition as one of the big challenges of this problem, and addressing this, as the authors note implies at least extending the experiments to more downstream tasks and ideally designing a task-agnostic framework for the problem. This is inconsistent with what the authors say in the first section: “To address the first challenge -that data limitations are heavily task dependent- we focus on the case study of intensive care unit (ICU) data in particular”.
- [ ] Limited generalizability to other tasks, model classes, or more complex fairness definitions.

**Reviewer 3**
- [ ] Some claims made in the paper seem imprecise:  
	Sec. 1: “This setting is highly relevant when overall hospital performance is desired in conjunction with improving subgroup outcomes.”, what do the authors mean by “overall hospital performance”?  
	Sec. 3: “In a real-world setting, it is not ideal to throw away data”, in some settings discarding some data, for example because of bad data quality can be beneficial in terms of model performance.  
	Sec. 4: When the authors refer to a “sufficiently-large hospital”.
	
	When the authors say “In light of these findings, we propose a shift from post-processing fairness interventions like calibration towards data interventions which treat fairness as a first order goal rather than a post-hoc constraint.”, this does not seem to align with the fact the authors also perform experiments using calibration as a post-processing intervention (Fig. 6 and Fig. 7).
- [ ] In Sec. 5, when the authors say “One critical observation from 3 is that it suggests it is more important to understand the test distribution rather than just the added source distribution...”, it seems strange from a methodological perspective to try to decide on the actions to take based on test data. Normally a strict separation is enforced between test and train data to prevent overfitting and accurately evaluate the capacity to generalize of a model. The same problem arises when the authors say “The next data selection method we evaluated chooses the sources which are most similar to the test distribution.”.
