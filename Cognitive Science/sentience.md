Sentience is specifically used in the discussion of [[consciousness]] in [[artificial intelligence]]. There are a few different viewpoints we can take in this area.

**Weak AI -** if a machine passes the [[artificial intelligence#alan turing (1912 - 1954)|Turing Test]], then it behaves like a human
-   Weak AI machines are typically specialized and can perform limited tasks, seeing as it follows an algorithm that is bounded in robustness
**Strong AI -** if a machine passes the [[artificial intelligence#alan turing (1912 - 1954)|Turing Test]], then it is _thinking_ like a human, a truly intelligent machine

A hole in the Turing Test is that both weak and strong AI can pass the Turing Test, because the test does not asses the machine’s “thought” process, only its output responses to inputs.

## the chinese room experiment
Thought experiment conducted by John Searle in 1980. 
-   Replace a computer with a non-Chinese speaking human equipped with a comprehensive cheat sheet
-   A Chinese user passes the human an input, the human looks up the input in their cheat sheet, and it tells them what to output
-   The human still doesn’t understand Chinese, but always gives the correct output. Are they thinking, understanding, or truly intelligent?

**Conclusions**
-   Without _understanding_, the machine cannot be thinking
    -   The Strong AI Hypothesis is false

**Rebuttals to Chinese Room Experiment**
Systems Reply
-   Even though the man doesn’t understand Chinese, the overarching system _does_
Robot Reply
-   Even though the man in the box doesn’t understand Chinese, if a robot controlled by a computer was able to navigate the world and attach meanings to symbols, it would be _understanding language_
Brain Simulator Reply
-   If AI was redesigned to simulate the neuronal activity of a native Chinese speaker when speaking Chinese, AI _can understand_ Chinese just as a human speaker does